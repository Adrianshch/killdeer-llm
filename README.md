# killdeer-llm

# RAG vs. Fine Tuning video:
https://www.youtube.com/watch?v=00Q0G84kq3M 

DebunkBot:
https://www.debunkbot.com/ 

Fine tuning is a better choice because we are not dealing with dynamic data and we will benefit from speed and reduced size of the model and cutoff is not a concern for us.

Ideas:
1. AITA LLM (easier)
2. Anti-polarization LLM


It looks like AWS Bedrock allows you to create a knowledge base (vector storage) and do fine-tuning. There is also something called AWS Lex that allows you to create a chatbot using the 
knowledge base. Unfortunately, it does cost a small amount of money (something like .00025 per use). 

Thoughts: 
1. A chatbot that helps ask critical thinking questions about polarizing political content
2. A chatbot that shows 5 different perspectives on a polarizing incident
3. A chatbot that annotates speech for logical fallacies (cherrypicking, appeal to fear, strawman)
4. When there is a lack of truth and prevalence of misinformation, we cannot count on AI to have an understanding of the truth... we can just guide the user with critical thinking questions
5. When it is politically unclear when othering is justified--ex trans people "grooming" vs republicans taking away the rights of trans people--we can figure out historical power structures. For example, who has typically had power--trans people or anti-trans people? You also try to understand money and corruption--Elon Musk and Doge. You can classify the threat both sides pose to each other--ex. threat to bodily safety, threat to scientific understanding, threat to lifestyle, threat to economy, threat of taking our liberties...
6. Some language will be an immediate turn-off to the right
